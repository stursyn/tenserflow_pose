{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 21:22:26,542\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from loguru import logger\n",
    "from PIL import Image\n",
    "import ray\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_shards = 64\n",
    "num_val_shards = 8\n",
    "ray.init()\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n - 1):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    results.append(l[start:])\n",
    "    return results\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy(\n",
    "        )  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreate_tfexample(anno):\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    x = [\n",
    "        joint[0] / width if joint[0] >= 0 else joint[0]\n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        joint[1] / height if joint[1] >= 0 else joint[0]\n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    # 0 - invisible, 1 - occluded, 2 - visible\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=list(map(int, x)))),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=list(map(int, y)))),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=list(map(int, v)))),\n",
    "        'image/object/center/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[int(width / 2)])),\n",
    "        'image/object/center/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[int(height / 2)])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[width * height])),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "#     feature = {}\n",
    "#     feature['image/height'] = tf.train.Feature(int64_list=tf.train.Int64List(value = [height]))\n",
    "#     feature['image/width'] = tf.train.Feature(int64_list=tf.train.Int64List(value = [width]))\n",
    "#     feature['image/depth'] = tf.train.Feature(int64_list=tf.train.Int64List(value = [depth]))\n",
    "#     feature['image/object/parts/x'] = tf.train.Feature(int64_list=tf.train.Int64List(value = x))\n",
    "#     feature['image/object/parts/y'] = tf.train.Feature(int64_list=tf.train.Int64List(value = y))\n",
    "#     feature['image/object/parts/v'] = tf.train.Feature(int64_list=tf.train.Int64List(value = v))\n",
    "#     feature['image/encoded'] = _bytes_feature(content)\n",
    "#     feature['image/filename'] = _bytes_feature(filename.encode())\n",
    "    \n",
    "    features = tf.train.Features(feature=feature)\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno_list in chunk:\n",
    "            tf_example = genreate_tfexample(anno_list)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)\n",
    "\n",
    "\n",
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        # train_0001_of_0064.tfrecords\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, './tfrecords/{}_{}_of_{}.tfrecords'.format(\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)\n",
    "\n",
    "\n",
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "    }\n",
    "    return annotation\n",
    "\n",
    "\n",
    "# def main():\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to parse annotations.\n",
      "First train annotation:  {'filename': '015601864.jpg', 'filepath': './mpii/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]]}\n",
      "First val annotation:  {'filename': '005808361.jpg', 'filepath': './mpii/images/005808361.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[804.0, 711.0], [816.0, 510.0], [908.0, 438.0], [1040.0, 454.0], [906.0, 528.0], [883.0, 707.0], [974.0, 446.0], [985.0, 253.0], [982.7591, 235.9694], [962.2409, 80.0306], [869.0, 214.0], [798.0, 340.0], [902.0, 253.0], [1067.0, 253.0], [1167.0, 353.0], [1142.0, 478.0]]}\n",
      "Start to build TF Records.\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0022_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0022_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0042_of_0064.tfrecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0045_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0042_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0045_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m start to build tf records for ./tfrecords/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m start to build tf records for ./tfrecords/val_0007_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m start to build tf records for ./tfrecords/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m start to build tf records for ./tfrecords/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m start to build tf records for ./tfrecords/val_0008_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m start to build tf records for ./tfrecords/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m start to build tf records for ./tfrecords/val_0005_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m start to build tf records for ./tfrecords/val_0006_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71028)\u001b[0m finished building tf records for ./tfrecords/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71031)\u001b[0m finished building tf records for ./tfrecords/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71027)\u001b[0m finished building tf records for ./tfrecords/val_0005_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71024)\u001b[0m finished building tf records for ./tfrecords/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71030)\u001b[0m finished building tf records for ./tfrecords/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71026)\u001b[0m finished building tf records for ./tfrecords/val_0007_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(pid=71025)\u001b[0m finished building tf records for ./tfrecords/val_0006_of_0008.tfrecords\n",
      "Successfully wrote 25204 annotations to TF Records.\n",
      "\u001b[2m\u001b[36m(pid=71029)\u001b[0m finished building tf records for ./tfrecords/val_0008_of_0008.tfrecords\n"
     ]
    }
   ],
   "source": [
    "print('Start to parse annotations.')\n",
    "if not os.path.exists('./tfrecords'):\n",
    "    os.makedirs('./tfrecords')\n",
    "\n",
    "with open('./mpii_human_pose_v1_u12_2/train.json') as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    train_annotations = [\n",
    "        parse_one_annotation(anno, './mpii/images/')\n",
    "        for anno in train_annos\n",
    "    ]\n",
    "    print('First train annotation: ', train_annotations[0])\n",
    "    del (train_annos)\n",
    "\n",
    "with open('./mpii_human_pose_v1_u12_2/validation.json') as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "    val_annotations = [\n",
    "        parse_one_annotation(anno, './mpii/images/') for anno in val_annos\n",
    "    ]\n",
    "    print('First val annotation: ', val_annotations[0])\n",
    "    del (val_annos)\n",
    "\n",
    "print('Start to build TF Records.')\n",
    "build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "    len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
